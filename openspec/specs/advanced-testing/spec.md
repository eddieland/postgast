# advanced-testing Specification

## Purpose

Robustness testing beyond standard unit tests: fuzz testing with Hypothesis for crash-freedom, stress testing with large
and deeply nested inputs, and boundary testing for edge cases like null bytes, control characters, and Unicode.

______________________________________________________________________

## Fuzz Testing

### Requirement: Crash-freedom for string-accepting functions

Each public function that accepts a SQL string input (`parse`, `normalize`, `fingerprint`, `scan`, `split`) SHALL either
return a valid result or raise `PgQueryError` for any input string. The function MUST NOT segfault, hang, raise
`SystemError`, or produce undefined behavior regardless of input content, encoding, or length.

#### Scenario: Arbitrary Unicode text does not crash parse

- **WHEN** `parse` is called with an arbitrary Unicode string generated by Hypothesis
- **THEN** the call either returns a `ParseResult` or raises `PgQueryError`

#### Scenario: Arbitrary Unicode text does not crash normalize

- **WHEN** `normalize` is called with an arbitrary Unicode string generated by Hypothesis
- **THEN** the call either returns a `str` or raises `PgQueryError`

#### Scenario: Arbitrary Unicode text does not crash fingerprint

- **WHEN** `fingerprint` is called with an arbitrary Unicode string generated by Hypothesis
- **THEN** the call either returns a `FingerprintResult` or raises `PgQueryError`

#### Scenario: Arbitrary Unicode text does not crash scan

- **WHEN** `scan` is called with an arbitrary Unicode string generated by Hypothesis
- **THEN** the call either returns a `ScanResult` or raises `PgQueryError`

#### Scenario: Arbitrary Unicode text does not crash split

- **WHEN** `split` is called with an arbitrary Unicode string generated by Hypothesis
- **THEN** the call either returns a `list[str]` or raises `PgQueryError`

### Requirement: Crash-freedom for deparse with mutated ASTs

The `deparse` function SHALL either return a valid SQL string or raise `PgQueryError` when given a protobuf
`ParseResult` that has been parsed from valid SQL and then mutated. It MUST NOT segfault or produce undefined behavior.

#### Scenario: Parse-then-deparse roundtrip does not crash

- **WHEN** a valid SQL statement is parsed into a `ParseResult` and then deparsed
- **THEN** the call returns a SQL string without crashing

#### Scenario: Deparsing a mutated parse tree does not crash

- **WHEN** a valid SQL statement is parsed, the resulting `ParseResult` is mutated (fields cleared, values changed), and
  then deparsed
- **THEN** the call either returns a `str` or raises `PgQueryError`

### Requirement: SQL-biased input generation

The fuzz test input strategy SHALL include SQL-flavored inputs in addition to purely random text. This MUST include
strings composed of SQL keywords, operators, punctuation, identifiers, and literals to exercise interesting parser code
paths beyond what random bytes would reach.

#### Scenario: SQL fragment inputs exercise parser paths

- **WHEN** fuzz tests run with the SQL-biased strategy
- **THEN** generated inputs include combinations of SQL keywords (`SELECT`, `FROM`, `WHERE`, etc.), operators (`=`,
  `<>`, `||`), punctuation (`;`, `(`, `)`, `'`, `"`), and numeric/string literals

### Requirement: Edge-case input coverage

The fuzz test input strategy SHALL include known edge-case inputs: empty strings, strings containing null bytes, very
long strings (up to 100KB), and deeply nested parenthesized expressions.

#### Scenario: Empty string input

- **WHEN** any string-accepting function is called with an empty string `""`
- **THEN** the call either returns a valid result or raises `PgQueryError`

#### Scenario: Null byte input

- **WHEN** any string-accepting function is called with a string containing embedded null bytes
- **THEN** the call either returns a valid result or raises `PgQueryError`

#### Scenario: Very long input

- **WHEN** any string-accepting function is called with a string up to 100KB in length
- **THEN** the call either returns a valid result or raises `PgQueryError`

### Requirement: Fuzz tests are isolated from the default test suite

Fuzz tests SHALL be marked with `@pytest.mark.fuzz` and MUST NOT run as part of the default `make test` target. A
separate `make fuzz` target SHALL be provided to run fuzz tests on demand.

#### Scenario: Default test run excludes fuzz tests

- **WHEN** `make test` is run
- **THEN** no tests marked with `@pytest.mark.fuzz` are executed

#### Scenario: Fuzz target runs fuzz tests

- **WHEN** `make fuzz` is run
- **THEN** all tests marked with `@pytest.mark.fuzz` are executed

### Requirement: Configurable example count

The number of Hypothesis examples per test SHALL default to 1000 and MUST be overridable via the
`HYPOTHESIS_MAX_EXAMPLES` environment variable.

#### Scenario: Default example count

- **WHEN** fuzz tests run without `HYPOTHESIS_MAX_EXAMPLES` set
- **THEN** Hypothesis generates 1000 examples per test function

#### Scenario: Custom example count via environment variable

- **WHEN** fuzz tests run with `HYPOTHESIS_MAX_EXAMPLES=100`
- **THEN** Hypothesis generates 100 examples per test function

______________________________________________________________________

## Stress Testing

### Requirement: Large SQL input handling

Every core operation (parse, deparse, normalize, fingerprint, split, scan) SHALL handle SQL inputs up to 10 MB without
crashing. The operation SHALL either return a valid result or raise `PgQueryError`.

#### Scenario: Parse a large SELECT with many columns

- **WHEN** `parse()` is called with a SELECT containing 1,000 column expressions
- **THEN** it returns a `ParseResult` with one statement, or raises `PgQueryError`

#### Scenario: Normalize a large query

- **WHEN** `normalize()` is called with a SELECT containing 1,000 literal values
- **THEN** it returns a normalized string with placeholders, or raises `PgQueryError`

#### Scenario: Fingerprint a large query

- **WHEN** `fingerprint()` is called with a SELECT containing 1,000 column expressions
- **THEN** it returns a `FingerprintResult`, or raises `PgQueryError`

#### Scenario: Split a string with many statements

- **WHEN** `split()` is called with a string containing 1,000 semicolon-separated statements
- **THEN** it returns a list of 1,000 statements, or raises `PgQueryError`

#### Scenario: Scan a large query

- **WHEN** `scan()` is called with a SELECT containing 1,000 column expressions
- **THEN** it returns a `ScanResult` with tokens, or raises `PgQueryError`

#### Scenario: Deparse a large parse result

- **WHEN** a large SELECT with 1,000 columns is parsed and the resulting protobuf is passed to `deparse()`
- **THEN** it returns a SQL string, or raises `PgQueryError`

### Requirement: Deeply nested expression handling

Every core operation SHALL handle deeply nested SQL expressions (up to 500 levels) without crashing. The operation SHALL
either return a valid result or raise `PgQueryError`.

#### Scenario: Parse deeply nested parenthesized expressions

- **WHEN** `parse()` is called with `SELECT` followed by 500 levels of nested parentheses around a literal (e.g.,
  `SELECT ((((...1...))))`)
- **THEN** it returns a `ParseResult` or raises `PgQueryError`

#### Scenario: Parse deeply nested subqueries

- **WHEN** `parse()` is called with 100 levels of nested subqueries (e.g.,
  `SELECT * FROM (SELECT * FROM (... SELECT 1 ...))`)
- **THEN** it returns a `ParseResult` or raises `PgQueryError`

#### Scenario: Normalize deeply nested expression

- **WHEN** `normalize()` is called with 500 levels of nested parenthesized expressions
- **THEN** it returns a string or raises `PgQueryError`

#### Scenario: Fingerprint deeply nested expression

- **WHEN** `fingerprint()` is called with 500 levels of nested parenthesized expressions
- **THEN** it returns a `FingerprintResult` or raises `PgQueryError`

#### Scenario: Split input containing deeply nested query

- **WHEN** `split()` is called with a string containing a deeply nested query
- **THEN** it returns a list or raises `PgQueryError`

#### Scenario: Scan deeply nested expression

- **WHEN** `scan()` is called with 500 levels of nested parenthesized expressions
- **THEN** it returns a `ScanResult` or raises `PgQueryError`

### Requirement: Wide query handling

Every core operation SHALL handle queries with a large number of JOINs, parameters, or CASE branches without crashing.

#### Scenario: Parse a query with many JOINs

- **WHEN** `parse()` is called with a SELECT joining 50 tables
- **THEN** it returns a `ParseResult` or raises `PgQueryError`

#### Scenario: Parse a query with many CASE branches

- **WHEN** `parse()` is called with a CASE expression containing 500 WHEN clauses
- **THEN** it returns a `ParseResult` or raises `PgQueryError`

#### Scenario: Normalize a query with many parameters

- **WHEN** `normalize()` is called with a query containing 1,000 literal values in an IN list
- **THEN** it returns a normalized string or raises `PgQueryError`

### Requirement: Stress tests are marked for selective execution

All stress tests SHALL be marked with `@pytest.mark.stress` so they can be excluded from fast CI runs via
`pytest -m "not stress"`.

#### Scenario: Stress marker is registered

- **WHEN** pytest collects tests
- **THEN** the `stress` marker is registered in `pyproject.toml` and produces no unknown-marker warnings

#### Scenario: Stress tests are skippable

- **WHEN** pytest is invoked with `-m "not stress"`
- **THEN** no tests from `test_stress.py` are collected, and all tests from `test_boundary.py` are still collected

______________________________________________________________________

## Boundary Testing

### Requirement: Null byte handling

Every core operation (parse, deparse, normalize, fingerprint, split, scan) SHALL handle input containing embedded null
bytes (`\x00`) without crashing. The operation SHALL either return a result (possibly truncated at the null byte) or
raise `PgQueryError`.

#### Scenario: Parse SQL with embedded null byte

- **WHEN** `parse()` is called with `"SELECT\x001"`
- **THEN** it returns a `ParseResult` or raises `PgQueryError` â€” no crash

#### Scenario: Normalize SQL with embedded null byte

- **WHEN** `normalize()` is called with `"SELECT\x001"`
- **THEN** it returns a string or raises `PgQueryError` â€” no crash

#### Scenario: Fingerprint SQL with embedded null byte

- **WHEN** `fingerprint()` is called with `"SELECT\x001"`
- **THEN** it returns a `FingerprintResult` or raises `PgQueryError` â€” no crash

#### Scenario: Split SQL with embedded null byte

- **WHEN** `split()` is called with `"SELECT 1;\x00SELECT 2"`
- **THEN** it returns a list or raises `PgQueryError` â€” no crash

#### Scenario: Scan SQL with embedded null byte

- **WHEN** `scan()` is called with `"SELECT\x001"`
- **THEN** it returns a `ScanResult` or raises `PgQueryError` â€” no crash

### Requirement: Control character handling

Every core operation SHALL handle input containing ASCII control characters (tabs, vertical tabs, form feeds, backspace,
bell) without crashing.

#### Scenario: Parse SQL with control characters

- **WHEN** `parse()` is called with SQL containing `\t`, `\v`, `\f`, `\b`, or `\a` characters
- **THEN** it returns a `ParseResult` or raises `PgQueryError` â€” no crash

#### Scenario: Scan SQL with control characters

- **WHEN** `scan()` is called with SQL containing control characters
- **THEN** it returns a `ScanResult` or raises `PgQueryError` â€” no crash

### Requirement: Unicode edge case handling

Every core operation SHALL handle input containing non-BMP Unicode characters (emoji, CJK supplementary), zero-width
characters, and Unicode edge cases without crashing.

#### Scenario: Parse SQL with emoji in string literal

- **WHEN** `parse()` is called with `SELECT 'ðŸŽ‰ðŸš€'`
- **THEN** it returns a `ParseResult` with one statement

#### Scenario: Parse SQL with zero-width characters in identifier

- **WHEN** `parse()` is called with SQL containing zero-width spaces (`\u200b`) or zero-width joiners (`\u200d`) in
  identifiers
- **THEN** it returns a `ParseResult` or raises `PgQueryError` â€” no crash

#### Scenario: Scan SQL with non-BMP codepoints

- **WHEN** `scan()` is called with SQL containing emoji or CJK supplementary characters
- **THEN** it returns a `ScanResult` or raises `PgQueryError` â€” no crash

#### Scenario: Split SQL with multi-byte Unicode

- **WHEN** `split()` is called with `"SELECT 'ðŸŽ‰'; SELECT 'æ—¥æœ¬èªž'"`
- **THEN** it returns a list of two statements or raises `PgQueryError` â€” no crash

### Requirement: Malformed SQL error handling

Every core operation that accepts raw SQL SHALL raise `PgQueryError` (not crash) when given systematically malformed
inputs: unterminated strings, unterminated comments, mismatched parentheses, partial statements, and garbage bytes.

#### Scenario: Parse unterminated string literal

- **WHEN** `parse()` is called with `"SELECT 'unterminated"`
- **THEN** it raises `PgQueryError`

#### Scenario: Parse unterminated block comment

- **WHEN** `parse()` is called with `"SELECT /* never closed"`
- **THEN** it raises `PgQueryError`

#### Scenario: Parse mismatched parentheses

- **WHEN** `parse()` is called with `"SELECT ((1)"`
- **THEN** it raises `PgQueryError`

#### Scenario: Parse partial statement

- **WHEN** `parse()` is called with `"SELECT"`, `"INSERT INTO"`, or `"CREATE TABLE"`
- **THEN** it raises `PgQueryError`

#### Scenario: Normalize malformed SQL

- **WHEN** `normalize()` is called with malformed SQL (unterminated strings, mismatched parens)
- **THEN** it raises `PgQueryError`

#### Scenario: Fingerprint malformed SQL

- **WHEN** `fingerprint()` is called with malformed SQL
- **THEN** it raises `PgQueryError`

#### Scenario: Split unterminated construct

- **WHEN** `split()` is called with `"SELECT 'unterminated; SELECT 2"`
- **THEN** it raises `PgQueryError`

#### Scenario: Scan garbage bytes

- **WHEN** `scan()` is called with random bytes decoded as a string
- **THEN** it returns a `ScanResult` (possibly with error tokens) or raises `PgQueryError` â€” no crash

### Requirement: Extremely long identifiers and string literals

Every core operation SHALL handle SQL containing identifiers or string literals at extreme lengths (100 KB+) without
crashing.

#### Scenario: Parse SQL with a very long identifier

- **WHEN** `parse()` is called with `SELECT` followed by a quoted identifier of 100,000 characters
- **THEN** it returns a `ParseResult` or raises `PgQueryError` â€” no crash

#### Scenario: Parse SQL with a very long string literal

- **WHEN** `parse()` is called with `SELECT` followed by a string literal of 100,000 characters
- **THEN** it returns a `ParseResult` or raises `PgQueryError` â€” no crash

#### Scenario: Scan SQL with a very long token

- **WHEN** `scan()` is called with a string literal of 100,000 characters
- **THEN** it returns a `ScanResult` or raises `PgQueryError` â€” no crash

### Requirement: Error resilience across sequential calls

The library SHALL not leak state between calls. After a call that raises `PgQueryError`, the next call with valid SQL
SHALL succeed normally.

#### Scenario: Parse succeeds after prior parse error

- **WHEN** `parse()` is called with invalid SQL and raises `PgQueryError`, then `parse()` is called with `"SELECT 1"`
- **THEN** the second call returns a valid `ParseResult` with one statement

#### Scenario: All operations succeed after prior errors

- **WHEN** each of parse, normalize, fingerprint, split, and scan is called with invalid SQL (each raising
  `PgQueryError`), then each is called again with valid SQL
- **THEN** every second call succeeds with a valid result

#### Scenario: No state leakage across many error-success cycles

- **WHEN** 100 cycles of (invalid SQL -> `PgQueryError`, valid SQL -> success) are executed against `parse()`
- **THEN** every valid-SQL call returns a correct `ParseResult`
